{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23 RNNs for Language Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Code largely adapted from https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1994 Super Famicom Fighting Baseball: The game included the 1993 season's major league players and stats thanks to its MLBPA license. The Japanese version of Fighting Baseball, did *not* have the MLBPA licence. Therefore they couldn't use player names.  Instead, someone had to make up plausibly \"American\"-sounding names.\n",
    "\n",
    "<img src=\"https://i.imgur.com/KJJOKTS.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag yourself, I'm Mike Truk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some \"American\" (English) names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import some data, so we'll use the same data we'll use in the implementation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 letters: [abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-]\n"
     ]
    }
   ],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "print(\"%s letters: [%s]\" % (n_letters, all_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFiles(path):\n",
    "    return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 19 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Hindi', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/surnames/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "# test non-ASCII character handling\n",
    "# slightly problematic choice\n",
    "# using 'n' for 'ñ' is like deciding it's not importatnt to type Ts anymore\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sampling of names from each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arabic</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Czech</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Irish</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Scottish</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Koury</td>\n",
       "      <td>Bian</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Ven</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Rosenberger</td>\n",
       "      <td>Banos</td>\n",
       "      <td>Ramakan</td>\n",
       "      <td>Raghailligh</td>\n",
       "      <td>Nicolosi</td>\n",
       "      <td>Isobe</td>\n",
       "      <td>Jang</td>\n",
       "      <td>Gorka</td>\n",
       "      <td>Barros</td>\n",
       "      <td>Avtukhov</td>\n",
       "      <td>Jamieson</td>\n",
       "      <td>Elizondo</td>\n",
       "      <td>Ngo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nazari</td>\n",
       "      <td>Chu</td>\n",
       "      <td>Weisener</td>\n",
       "      <td>Kloet</td>\n",
       "      <td>Timney</td>\n",
       "      <td>Deschamps</td>\n",
       "      <td>Vogel</td>\n",
       "      <td>Liatos</td>\n",
       "      <td>Medapati</td>\n",
       "      <td>Gallchobhar</td>\n",
       "      <td>Aquila</td>\n",
       "      <td>Sasaki</td>\n",
       "      <td>Choi</td>\n",
       "      <td>Nowak</td>\n",
       "      <td>Pinheiro</td>\n",
       "      <td>Jarikhin</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>Mata</td>\n",
       "      <td>Quang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nazari</td>\n",
       "      <td>Man</td>\n",
       "      <td>Kuffel</td>\n",
       "      <td>Paulis</td>\n",
       "      <td>Wickens</td>\n",
       "      <td>Sartre</td>\n",
       "      <td>Drechsler</td>\n",
       "      <td>Zouvelekis</td>\n",
       "      <td>Vinata</td>\n",
       "      <td>Niadh</td>\n",
       "      <td>Lecce</td>\n",
       "      <td>Shiga</td>\n",
       "      <td>Yeo</td>\n",
       "      <td>Sokolowski</td>\n",
       "      <td>De santigo</td>\n",
       "      <td>Babadjanyan</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>Silva</td>\n",
       "      <td>Ngo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nahas</td>\n",
       "      <td>Kau</td>\n",
       "      <td>Semick</td>\n",
       "      <td>Roggeveen</td>\n",
       "      <td>Ridle</td>\n",
       "      <td>Parent</td>\n",
       "      <td>Bohler</td>\n",
       "      <td>Poniros</td>\n",
       "      <td>Nergis</td>\n",
       "      <td>Ceallachan</td>\n",
       "      <td>Roma</td>\n",
       "      <td>Arakawa</td>\n",
       "      <td>Chung</td>\n",
       "      <td>Gorecki</td>\n",
       "      <td>Freitas</td>\n",
       "      <td>Aurov</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>Armando</td>\n",
       "      <td>Hoang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sabbag</td>\n",
       "      <td>Shan</td>\n",
       "      <td>Sabol</td>\n",
       "      <td>Nifterik</td>\n",
       "      <td>Karim</td>\n",
       "      <td>Faucher</td>\n",
       "      <td>Oppenheimer</td>\n",
       "      <td>Pantelas</td>\n",
       "      <td>Sritharan</td>\n",
       "      <td>O'Hannagain</td>\n",
       "      <td>Confortola</td>\n",
       "      <td>Tayama</td>\n",
       "      <td>Chun</td>\n",
       "      <td>Wojewodka</td>\n",
       "      <td>Almeida</td>\n",
       "      <td>Detengof</td>\n",
       "      <td>Craig</td>\n",
       "      <td>D'cruze</td>\n",
       "      <td>Vuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shamon</td>\n",
       "      <td>Lin</td>\n",
       "      <td>Krawiec</td>\n",
       "      <td>Kanne</td>\n",
       "      <td>Wareing</td>\n",
       "      <td>Foss</td>\n",
       "      <td>Lowe</td>\n",
       "      <td>Phocas</td>\n",
       "      <td>Malipatlolla</td>\n",
       "      <td>O'Keeffe</td>\n",
       "      <td>Alesci</td>\n",
       "      <td>Yoshikawa</td>\n",
       "      <td>Tsai</td>\n",
       "      <td>Pakulski</td>\n",
       "      <td>Guerra</td>\n",
       "      <td>Bacherikov</td>\n",
       "      <td>Davidson</td>\n",
       "      <td>Terrazas</td>\n",
       "      <td>Vinh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bazzi</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>Piller</td>\n",
       "      <td>Hanraets</td>\n",
       "      <td>Bannister</td>\n",
       "      <td>Guerin</td>\n",
       "      <td>Havener</td>\n",
       "      <td>Gavril</td>\n",
       "      <td>Barot</td>\n",
       "      <td>Flann</td>\n",
       "      <td>Adami</td>\n",
       "      <td>Sakoda</td>\n",
       "      <td>Jeong</td>\n",
       "      <td>Jelen</td>\n",
       "      <td>Magalhaes</td>\n",
       "      <td>Pismanik</td>\n",
       "      <td>Reid</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kattan</td>\n",
       "      <td>Seto</td>\n",
       "      <td>Neisser</td>\n",
       "      <td>Merckx</td>\n",
       "      <td>Reeve</td>\n",
       "      <td>Giroux</td>\n",
       "      <td>Bleier</td>\n",
       "      <td>Poniros</td>\n",
       "      <td>Kalpna</td>\n",
       "      <td>Eoghan</td>\n",
       "      <td>Longo</td>\n",
       "      <td>Oishi</td>\n",
       "      <td>Jo</td>\n",
       "      <td>Janda</td>\n",
       "      <td>Mata</td>\n",
       "      <td>Abutaliev</td>\n",
       "      <td>Bell</td>\n",
       "      <td>Maria</td>\n",
       "      <td>Chau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sabbagh</td>\n",
       "      <td>Dan</td>\n",
       "      <td>Slapnickova</td>\n",
       "      <td>Snijders</td>\n",
       "      <td>Caton</td>\n",
       "      <td>Proulx</td>\n",
       "      <td>Meissner</td>\n",
       "      <td>Koumanidis</td>\n",
       "      <td>Shivani</td>\n",
       "      <td>Rinn</td>\n",
       "      <td>Pisani</td>\n",
       "      <td>Isobe</td>\n",
       "      <td>Suh</td>\n",
       "      <td>Szewc</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>Talvir</td>\n",
       "      <td>Scott</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>Nghiem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cham</td>\n",
       "      <td>Wen</td>\n",
       "      <td>Jarzembowski</td>\n",
       "      <td>Aalst</td>\n",
       "      <td>Baxter</td>\n",
       "      <td>Fabian</td>\n",
       "      <td>Tangeman</td>\n",
       "      <td>Sotiris</td>\n",
       "      <td>Pyara</td>\n",
       "      <td>Maceachthighearna</td>\n",
       "      <td>Castro</td>\n",
       "      <td>Kawabata</td>\n",
       "      <td>Yu</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>Shamaev</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>Urbina</td>\n",
       "      <td>Vuu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Arabic Chinese         Czech      Dutch    English     French  \\\n",
       "0    Koury    Bian        Victor        Ven       Lyon     Robert   \n",
       "1   Nazari     Chu      Weisener      Kloet     Timney  Deschamps   \n",
       "2   Nazari     Man        Kuffel     Paulis    Wickens     Sartre   \n",
       "3    Nahas     Kau        Semick  Roggeveen      Ridle     Parent   \n",
       "4   Sabbag    Shan         Sabol   Nifterik      Karim    Faucher   \n",
       "5   Shamon     Lin       Krawiec      Kanne    Wareing       Foss   \n",
       "6    Bazzi     Zhu        Piller   Hanraets  Bannister     Guerin   \n",
       "7   Kattan    Seto       Neisser     Merckx      Reeve     Giroux   \n",
       "8  Sabbagh     Dan   Slapnickova   Snijders      Caton     Proulx   \n",
       "9     Cham     Wen  Jarzembowski      Aalst     Baxter     Fabian   \n",
       "\n",
       "        German       Greek         Hindi              Irish     Italian  \\\n",
       "0  Rosenberger       Banos       Ramakan        Raghailligh    Nicolosi   \n",
       "1        Vogel      Liatos      Medapati        Gallchobhar      Aquila   \n",
       "2    Drechsler  Zouvelekis        Vinata              Niadh       Lecce   \n",
       "3       Bohler     Poniros        Nergis         Ceallachan        Roma   \n",
       "4  Oppenheimer    Pantelas     Sritharan        O'Hannagain  Confortola   \n",
       "5         Lowe      Phocas  Malipatlolla           O'Keeffe      Alesci   \n",
       "6      Havener      Gavril         Barot              Flann       Adami   \n",
       "7       Bleier     Poniros        Kalpna             Eoghan       Longo   \n",
       "8     Meissner  Koumanidis       Shivani               Rinn      Pisani   \n",
       "9     Tangeman     Sotiris         Pyara  Maceachthighearna      Castro   \n",
       "\n",
       "    Japanese Korean      Polish   Portuguese      Russian   Scottish  \\\n",
       "0      Isobe   Jang       Gorka       Barros     Avtukhov   Jamieson   \n",
       "1     Sasaki   Choi       Nowak     Pinheiro     Jarikhin   Campbell   \n",
       "2      Shiga    Yeo  Sokolowski   De santigo  Babadjanyan    Cameron   \n",
       "3    Arakawa  Chung     Gorecki      Freitas        Aurov     Hunter   \n",
       "4     Tayama   Chun   Wojewodka      Almeida     Detengof      Craig   \n",
       "5  Yoshikawa  Tsai     Pakulski       Guerra   Bacherikov   Davidson   \n",
       "6     Sakoda  Jeong       Jelen    Magalhaes     Pismanik       Reid   \n",
       "7      Oishi     Jo       Janda         Mata    Abutaliev       Bell   \n",
       "8      Isobe    Suh       Szewc      Pereira       Talvir      Scott   \n",
       "9   Kawabata     Yu      Jordan  Albuquerque      Shamaev  Johnstone   \n",
       "\n",
       "    Spanish Vietnamese  \n",
       "0  Elizondo        Ngo  \n",
       "1      Mata      Quang  \n",
       "2     Silva        Ngo  \n",
       "3   Armando      Hoang  \n",
       "4   D'cruze        Vuu  \n",
       "5  Terrazas       Vinh  \n",
       "6  Valencia        Van  \n",
       "7     Maria       Chau  \n",
       "8    Rivera     Nghiem  \n",
       "9    Urbina        Vuu  "
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = {language : [int(np.random.uniform()*len(category_lines[language])) for i in range(10)] for language in all_categories}\n",
    "choices = {language : [category_lines[language][c] for  c in choices[language]] for language in choices}\n",
    "df = pandas.DataFrame(choices)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we quantify the differences between these names?  Well, we could try counting characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ('Hindi', 18),\n",
       " 'b': ('Arabic', 5),\n",
       " 'c': ('Italian', 6),\n",
       " 'd': ('Polish', 3),\n",
       " 'e': ('German', 18),\n",
       " 'f': ('French', 3),\n",
       " 'g': ('Irish', 6),\n",
       " 'h': ('Irish', 11),\n",
       " 'i': ('Greek', 9),\n",
       " 'j': ('Polish', 4),\n",
       " 'k': ('Polish', 8),\n",
       " 'l': ('Irish', 7),\n",
       " 'm': ('German', 3),\n",
       " 'n': ('Irish', 11),\n",
       " 'o': ('Greek', 10),\n",
       " 'p': ('Greek', 4),\n",
       " 'q': ('Portuguese', 2),\n",
       " 'r': ('German', 10),\n",
       " 's': ('Greek', 10),\n",
       " 't': ('Hindi', 5),\n",
       " 'u': ('Vietnamese', 6),\n",
       " 'v': ('Russian', 7),\n",
       " 'w': ('Polish', 5),\n",
       " 'x': ('French', 2),\n",
       " 'y': ('English', 2),\n",
       " 'z': ('Arabic', 4)}"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "{c : max({language : \n",
    "          sum([name.lower().count(c) for name in choices[language]]) \n",
    "          for language in all_categories}.items(), key=operator.itemgetter(1)) for c in all_letters[:26]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So maybe a Hindi name should have more As and a Polish name has more Zs (makes sense...)\n",
    "\n",
    "But..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Aaaaa \\leftarrow$ not a good Hindi name.\n",
    "\n",
    "$Zzzzz \\leftarrow$ not a good Polish name.\n",
    "\n",
    "What matters is how the letters go together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lyon',\n",
       " 'Timney',\n",
       " 'Wickens',\n",
       " 'Ridle',\n",
       " 'Karim',\n",
       " 'Wareing',\n",
       " 'Bannister',\n",
       " 'Reeve',\n",
       " 'Caton',\n",
       " 'Baxter']"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_eng = choices['English']\n",
    "sample_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g., What's the probability that $l_t$, the letter at position $t$ is '$r$', given than $l_{t-1}$ is '$a$'?\n",
    "\n",
    "$P(l_t=\\textsf{'}r\\textsf{'}|l_{t-1}=\\textsf{'}a\\textsf{'}) = ?$\n",
    "\n",
    "$P(Y|X) = \\frac{C(X,Y)}{C(X)}$\n",
    "\n",
    "$P(\\textsf{'}r\\textsf{'}|\\textsf{'}a\\textsf{'}) = \\frac{C(\\textsf{'}a\\textsf{'},\\textsf{'}r\\textsf{'})}{C(\\textsf{'}a\\textsf{'})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 across the above random sample\n",
      "0.18038147138964578 across all English names in the data\n"
     ]
    }
   ],
   "source": [
    "c1 = 'a'\n",
    "c2 = 'r'\n",
    "\n",
    "count1 = 0\n",
    "count1_2 = 0\n",
    "for name in sample_eng:\n",
    "    for i in range(len(name)-1):\n",
    "        count1_2 += np.sum(list(name.lower())[i:i+2] == [c1,c2])\n",
    "        count1 += np.sum(list(name.lower())[i:i+1] == [c1])\n",
    "print(\"%s across the above random sample\" % (count1_2/count1))\n",
    "\n",
    "count1 = 0\n",
    "count1_2 = 0\n",
    "for name in category_lines['English']:\n",
    "    for i in range(len(name)-1):\n",
    "        count1_2 += np.sum(list(name.lower())[i:i+2] == [c1,c2])\n",
    "        count1 += np.sum(list(name.lower())[i:i+1] == [c1])\n",
    "print(\"%s across all English names in the data\" % (count1_2/count1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English\n",
    "\n",
    "We know what spellings look like plausible English and what don't:\n",
    "\n",
    "$V = \\{e, g, p, r, s\\}$\n",
    "\n",
    "Plausible (fake) English words: $spreg$, $pregs$, $sperg$, $gresp$, $greps$.\n",
    "\n",
    "Impossible English words: $sgerp$, $egrsp$, $psegr$, etc.\n",
    "\n",
    "### Spanish or Welsh?\n",
    "\n",
    "Both Spanish and Welsh use the digraph \\<ll\\>.\n",
    "\n",
    "Talk this word beginning: *llan-*.  What comes next?\n",
    "\n",
    "*Llan-* ***o***: Spanish for \"plain\".\n",
    "\n",
    "*Llan-* ***f***: ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span style=\"color:white\">Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e8/Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch_station_sign_%28cropped_version_1%29.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know a language, you have a lot of implicit knowledge about the patterns that fit that language, for example, the way words are formed (morphology), sentence structure (syntax), or how sounds fit together (phonotactics).\n",
    "\n",
    "Spelling is a (very) rough approximation of phonotactics. **Order matters**.\n",
    "\n",
    "A computer doesn't have any of this knowledge.  It must learn the order in which letters occur appropriately for the language.  How can we teach it from looking at a bunch of samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks are generalizations of feedforward neural network that have \"memory\" in their hidden units. RNNs perform the same function for every input, but incorporate the output of the previous computation into the current one.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/627/1*go8PHsPNbbV6qRiwpUQ5BQ.png\">\n",
    "\n",
    "$x_t$ is passed through the weights ${\\bf A}$ to produce the output $h_t$.  ${\\bf A}$ will be comprised of (at least) 3 individual weight matrices: ${\\bf A}_i$, input layer weights; ${\\bf A}_h$, hidden layer weights; and ${\\bf A}_o$, output layer weights.\n",
    "\n",
    "$$h_t = f({\\bf A}_h h_{t-1}+{\\bf A}_i x_t), \\text{where } f \\text{ is the activation function}$$\n",
    "\n",
    "${\\bf A}_h$ are hidden layer weights, so ${\\bf H}$ ($h_t \\in {\\bf H}$) are hidden layer outputs that are included in the operation performed over the input ($x_t \\in {\\bf X}$) at the next timestep.\n",
    "\n",
    "Output computation:\n",
    "$$y_t = {\\bf A}_o h_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.2631355 , 0.28603912, 0.45082538]), array([0.21702309, 0.21279649, 0.57018042])]\n",
      "[2 2]\n",
      "Starting weights:\n",
      "[[0.41830005 0.60531251 0.46598094]\n",
      " [0.04284437 0.42414691 0.58003034]\n",
      " [0.77477335 0.72047926 0.21837831]\n",
      " [0.50284881 0.96262374 0.08994456]]\n",
      "[[0.84862148 0.96420535 0.43686078]\n",
      " [0.23316844 0.48079693 0.28488291]\n",
      " [0.29561181 0.83193022 0.22992977]\n",
      " [0.46565116 0.61042473 0.68453107]]\n",
      "[[0.29833955 0.66231601 0.38350276]\n",
      " [0.19346552 0.15260902 0.88175455]\n",
      " [0.73745634 0.30316706 0.96774616]\n",
      " [0.12247239 0.21615862 0.09480255]]\n",
      "\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a c c\n",
      "a b c\n",
      "Ending weights:\n",
      "[[ 0.41830005  0.60531251  0.46598094]\n",
      " [-0.65687065 -0.27556811 -0.11968468]\n",
      " [ 0.81079648  0.7565024   0.25440144]\n",
      " [-0.87679125 -0.41701632 -1.2896955 ]]\n",
      "[[ 0.84862148  0.96420535  0.43686078]\n",
      " [-0.15990944  0.08771905 -0.10819497]\n",
      " [ 0.17319641  0.70951481  0.10751437]\n",
      " [-0.12172172  0.02305186  0.09715819]]\n",
      "[[-5.48534119 -5.12136473 -5.40017798]\n",
      " [ 0.25003305  0.20917654  0.93832207]\n",
      " [ 7.35655367  6.92226439  7.58684349]\n",
      " [-1.3241112  -1.23042496 -1.35178103]]\n",
      "[array([0.30362207, 0.39635163, 0.3000263 ]), array([0.23100403, 0.22437191, 0.54462406])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a network to predict the following sequence: abc\n",
    "lr = 0.1\n",
    "\n",
    "# create target outputs as one-hot vectors (indicator variables)\n",
    "letters = ['a','b','c']\n",
    "T1 = np.array([0,1,0]) # b\n",
    "T2 = np.array([0,0,1]) # c\n",
    "\n",
    "# randomly initialize input hidden and output weights\n",
    "Ai = np.random.rand(4,3)\n",
    "Ah = np.random.rand(4,3)\n",
    "Ao = np.random.rand(4,3)\n",
    "\n",
    "# create input as one-hot vector\n",
    "X = np.array([[1,0,0]]) # a\n",
    "X = np.hstack([[[1]],X]) # add constant 1\n",
    "\n",
    "output = []\n",
    "\n",
    "H = np.tanh(X @ Ai)\n",
    "H = np.hstack([[[1]],H]) # add constant 1\n",
    "Y1 = softmax((H @ Ao).reshape(-1))\n",
    "output.append(Y1)\n",
    "\n",
    "Y1 = np.hstack([[1],Y1]) # add constant 1\n",
    "H = np.tanh((H @ Ah) + (Y1 @ Ai))\n",
    "H = np.hstack([[[1]],H]) # add constant 1\n",
    "Y2 = softmax((H @ Ao).reshape(-1))\n",
    "output.append(Y2)\n",
    "\n",
    "print(output)\n",
    "print(np.argmax(output,axis=1))\n",
    "\n",
    "print(\"Starting weights:\")\n",
    "print(Ai)\n",
    "print(Ah)\n",
    "print(Ao)\n",
    "print()\n",
    "\n",
    "for i in range(1000):\n",
    "    # compute hidden layer output\n",
    "    H = np.tanh(X @ Ai)\n",
    "    H = np.hstack([[[1]],H]) # add constant 1\n",
    "\n",
    "    # compute first output and error\n",
    "    Y1 = softmax((H @ Ao).reshape(-1))\n",
    "    err1 = T1-Y1\n",
    "\n",
    "    # NOW, compute hidden layer output using the second input\n",
    "    Y1 = np.hstack([[1],Y1]) # add constant 1\n",
    "    H = np.tanh((H @ Ah) + (Y1 @ Ai))\n",
    "    H = np.hstack([[[1]],H]) # add constant 1\n",
    "\n",
    "    # compute second output and error\n",
    "    Y2 = softmax((H @ Ao).reshape(-1))\n",
    "    err2 = T2-Y2\n",
    "    \n",
    "    Ai -= lr * ((err1/3) @ Ai.T * (1 - H ** 2)).reshape(-1,1)\n",
    "    Ah -= lr * ((err1/3) @ Ah.T * (1 - H ** 2)).reshape(-1,1)\n",
    "    Ao -= lr * ((err1/3) @ Ao.T).reshape(-1,1)\n",
    "    \n",
    "    Ai -= lr * ((err2/3) @ Ai.T * (1 - H ** 2)).reshape(-1,1)\n",
    "    Ah -= lr * ((err2/3) @ Ah.T * (1 - H ** 2)).reshape(-1,1)\n",
    "    Ao -= lr * ((err2/3) @ Ao.T).reshape(-1,1)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(letters[np.argmax(X.reshape(-1)[-3:])],letters[np.argmax(Y1[-3:])],letters[np.argmax(Y2[-3:])])\n",
    "\n",
    "print(\"Ending weights:\")\n",
    "print(Ai)\n",
    "print(Ah)\n",
    "print(Ao)\n",
    "\n",
    "output = []\n",
    "\n",
    "H = np.tanh(X @ Ai)\n",
    "H = np.hstack([[[1]],H]) # add constant 1\n",
    "Y1 = softmax((H @ Ao).reshape(-1))\n",
    "output.append(Y1)\n",
    "\n",
    "Y1 = np.hstack([[1],Y1]) # add constant 1\n",
    "H = np.tanh((H @ Ah) + (Y1 @ Ai))\n",
    "H = np.hstack([[[1]],H]) # add constant 1\n",
    "Y2 = softmax((H @ Ao).reshape(-1))\n",
    "output.append(Y2)\n",
    "\n",
    "print(output)\n",
    "np.argmax(output,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is very unreliable (try the above a few times---sometimes the output doesn't change much, or at all).  Rarely does it get it right.  Why?  We only have 1 sample!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something at scale using Pytorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1) # decrease odds of overfitting\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden # forward pass returns output value AND hidden layer value\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair(all_cats,lines):\n",
    "    category = randomChoice(all_cats)\n",
    "    line = randomChoice(lines[category])\n",
    "    return category, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience during training we’ll make a `randomTrainingExample` function that fetches a random (category, line) pair and turns them into the required (category, input, target) tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample(all_cats,lines):\n",
    "    category, line = randomTrainingPair(all_cats,lines)\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network\n",
    "\n",
    "In contrast to classification, where only the last output is used, we are making a prediction at every step, so we are calculating loss at every step.\n",
    "\n",
    "The magic of autograd allows you to simply sum these losses at each step and call backward at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # negative log likelihood loss\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(model, category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = model(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a `timeSince(timestamp)` function which returns a human readable string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_letter(output):\n",
    "    topv, topi = output.topk(1)\n",
    "    topi = topi[0][0]\n",
    "    if topi == n_letters - 1:\n",
    "        letter = \"\\0\"\n",
    "    else:\n",
    "        letter = all_letters[topi]\n",
    "        \n",
    "    return letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is business as usual - call train a bunch of times and wait a few minutes, printing the current time and loss every `print_every` examples, and keeping store of an average loss per `plot_every` examples in `all_losses` for plotting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (1000 10%) 3.5868\n",
      "0m 7s (2000 20%) 3.6053\n",
      "0m 10s (3000 30%) 3.4401\n",
      "0m 14s (4000 40%) 2.8736\n",
      "0m 17s (5000 50%) 2.7747\n",
      "0m 21s (6000 60%) 3.2269\n",
      "0m 24s (7000 70%) 2.9952\n",
      "0m 28s (8000 80%) 3.3042\n",
      "0m 31s (9000 90%) 2.8009\n",
      "0m 35s (10000 100%) 2.9865\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 10000\n",
    "print_every = 1000\n",
    "plot_every = 100\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    ex = randomTrainingExample(all_categories,category_lines)\n",
    "    output, loss = train(rnn,*ex)\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c1c51dfe88>]"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some outputs, starting with each letter of the alphabet in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(category, model, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = model.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = model(category_tensor, input[0], hidden)\n",
    "            letter = output_to_letter(output)\n",
    "            if letter == \"\\0\":\n",
    "                break\n",
    "            else:\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, model, start_letters='ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
    "    print(\"%s:\" % category)\n",
    "    for start_letter in start_letters:\n",
    "        s = [sample(category, model, start_letter) for i in range(3)]\n",
    "        print('\\t\\t'.join(set(s)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arabic': 'ARA', 'Chinese': 'CHI', 'Czech': 'CZE', 'Dutch': 'DUT', 'English': 'ENG', 'French': 'FRE', 'German': 'GER', 'Greek': 'GRE', 'Hindi': 'HIN', 'Irish': 'IRI', 'Italian': 'ITA', 'Japanese': 'JAP', 'Korean': 'KOR', 'Polish': 'POL', 'Portuguese': 'POR', 'Russian': 'RUS', 'Scottish': 'SCO', 'Spanish': 'SPA', 'Vietnamese': 'VIE'}\n"
     ]
    }
   ],
   "source": [
    "# there are the possible categories (languages)\n",
    "cat_to_code = {}\n",
    "for i in range(n_categories):\n",
    "    cat_to_code[all_categories[i]] = all_categories[i][:3].upper()\n",
    "print(cat_to_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic:\n",
      "Aana\t\tAarar\t\tAarara\n",
      "Barar\n",
      "Cana\t\tCora\t\tCarar\n",
      "Daar\t\tDara\n",
      "Earar\t\tEarer\n",
      "Farar\n",
      "Garar\n",
      "Harar\t\tHara\n",
      "Ioan\t\tIarara\t\tIarar\n",
      "Jarer\t\tJara\n",
      "Kara\n",
      "Larar\t\tLara\t\tLaner\n",
      "Mara\t\tMarra\n",
      "Nora\t\tNarer\n",
      "Ooara\t\tOarer\t\tOara\n",
      "Parar\t\tPara\n",
      "Qarer\t\tQarera\n",
      "Rarar\n",
      "Sarar\t\tSara\t\tSarara\n",
      "Taner\t\tToner\t\tTara\n",
      "Uarar\n",
      "Vara\n",
      "Wana\t\tWarar\n",
      "Xarar\n",
      "Yarar\t\tYara\n",
      "Zarar\t\tZarer\n",
      "\n",
      "Chinese:\n",
      "Aaner\t\tAane\t\tAare\n",
      "Bane\t\tBare\n",
      "Caner\t\tCane\n",
      "Don\t\tDan\n",
      "Ean\t\tEane\n",
      "Fane\n",
      "Gane\n",
      "Han\n",
      "Iare\t\tIane\n",
      "Jane\t\tJan\t\tJara\n",
      "Kana\t\tKan\n",
      "Lan\t\tLone\n",
      "Mane\t\tMan\n",
      "Nane\t\tNere\n",
      "Oane\n",
      "Pon\t\tPare\t\tPan\n",
      "Qane\t\tQaner\n",
      "Ran\n",
      "San\n",
      "Ton\t\tTan\n",
      "Uane\t\tUaan\n",
      "Van\t\tVane\n",
      "Wana\t\tWane\n",
      "Xare\t\tXane\n",
      "Yan\n",
      "Zere\t\tZan\t\tZane\n",
      "\n",
      "Czech:\n",
      "Aarer\t\tAarar\n",
      "Barar\t\tBanara\t\tBarer\n",
      "Carer\t\tCaner\t\tCarere\n",
      "Dorer\t\tDarer\n",
      "Eaner\t\tEaroe\t\tEarer\n",
      "Farer\t\tFarar\n",
      "Gorer\t\tGarer\n",
      "Harer\t\tHarere\n",
      "Iarer\n",
      "Jorer\t\tJarer\t\tJaner\n",
      "Karer\t\tKanar\n",
      "Larer\t\tLaree\n",
      "Maree\t\tMarar\t\tMarere\n",
      "Narer\t\tNarar\n",
      "Ooarere\t\tOanee\t\tOorer\n",
      "Parer\n",
      "Qarer\t\tQarar\n",
      "Rarer\t\tRarere\t\tRareer\n",
      "Sarer\n",
      "Tarer\n",
      "Uarer\n",
      "Varar\t\tVaner\t\tVarer\n",
      "Warer\n",
      "Xaneee\t\tXarar\n",
      "Yarer\t\tYarere\n",
      "Zarer\n",
      "\n",
      "Dutch:\n",
      "Aarer\n",
      "Baen\t\tBorer\t\tBarer\n",
      "Carer\t\tCarere\n",
      "Darer\t\tDaree\t\tDorrer\n",
      "Eaner\t\tEarar\n",
      "Farer\t\tForere\n",
      "Ganer\t\tGarer\n",
      "Harer\t\tHarare\t\tHorer\n",
      "Iarer\n",
      "Jerer\t\tJarer\n",
      "Karer\n",
      "Larer\t\tLaner\n",
      "Marar\t\tMarer\n",
      "Narer\n",
      "Oarer\t\tOarar\t\tOorer\n",
      "Parer\t\tPareer\n",
      "Qarer\t\tQarar\n",
      "Rarer\t\tRerrer\t\tRaner\n",
      "Sarer\t\tSarar\t\tSoner\n",
      "Tarer\n",
      "Uaner\t\tUarar\t\tUarer\n",
      "Varar\t\tVarer\n",
      "Ware\t\tWareee\t\tWarer\n",
      "Xoree\t\tXarra\t\tXarer\n",
      "Yarer\n",
      "Zarer\t\tZaree\t\tZareer\n",
      "\n",
      "English:\n",
      "Aarer\t\tAaner\t\tAanee\n",
      "Baarer\t\tBaner\n",
      "Carer\t\tCarar\n",
      "Darer\n",
      "Eaner\t\tEarer\n",
      "Farer\t\tForer\n",
      "Ganer\t\tGarer\n",
      "Harer\t\tHarere\n",
      "Iarer\t\tIaree\n",
      "Jarer\n",
      "Karer\t\tKaner\n",
      "Larar\t\tLarer\t\tLorer\n",
      "Maree\t\tMarer\t\tMaler\n",
      "Naner\t\tNare\t\tNarer\n",
      "Oarrer\t\tOarer\t\tOorer\n",
      "Parer\n",
      "Qaner\t\tQorer\n",
      "Rarer\n",
      "Saree\t\tSarer\t\tSaner\n",
      "Tarar\t\tTarer\n",
      "Uarer\t\tUarrer\n",
      "Varer\t\tVorer\n",
      "Waree\t\tWarar\t\tWarer\n",
      "Xaran\t\tXarer\n",
      "Yarer\t\tYorer\n",
      "Zarer\t\tZarere\n",
      "\n",
      "French:\n",
      "Aarer\t\tAarar\n",
      "Barer\n",
      "Carer\n",
      "Darer\n",
      "Earere\t\tEorere\t\tEarer\n",
      "Farer\t\tFarere\t\tFanar\n",
      "Garere\t\tGorer\t\tGarer\n",
      "Harer\n",
      "Iarer\t\tIaree\n",
      "Jaree\t\tJarer\n",
      "Karer\t\tKaner\n",
      "Larer\n",
      "Marer\t\tMarrer\n",
      "Narer\t\tNaren\n",
      "Oarer\t\tOoarer\n",
      "Paner\t\tParee\t\tPareee\n",
      "Qarrer\t\tQarer\t\tQanare\n",
      "Rarer\t\tRarar\n",
      "Sarar\t\tSarer\n",
      "Tarer\t\tToree\t\tTorer\n",
      "Uaner\t\tUarer\n",
      "Varer\n",
      "Waree\t\tWorar\t\tWoarer\n",
      "Xarer\n",
      "Yarer\t\tYarar\n",
      "Zaren\t\tZarere\t\tZaree\n",
      "\n",
      "German:\n",
      "Aarer\n",
      "Barere\t\tBanee\t\tBaner\n",
      "Carer\t\tConer\n",
      "Darer\n",
      "Eaner\t\tEarer\n",
      "Farer\t\tFarere\n",
      "Ganer\t\tGarer\n",
      "Harar\t\tHoarer\t\tHorer\n",
      "Iarer\t\tIaree\t\tIarar\n",
      "Jaree\t\tJaren\t\tJarer\n",
      "Karer\t\tKarar\n",
      "Larer\n",
      "Marer\n",
      "Nanar\t\tNarer\t\tNareer\n",
      "Oarer\t\tOorer\n",
      "Parer\t\tPoree\t\tPorer\n",
      "Qanere\t\tQaner\n",
      "Rarer\t\tRaree\n",
      "Sarer\n",
      "Tarer\n",
      "Uarer\n",
      "Varerar\t\tVarer\t\tVaner\n",
      "Worer\t\tWarer\n",
      "Xarer\t\tXaner\n",
      "Yarere\t\tYorer\t\tYarer\n",
      "Zaneer\t\tZarea\t\tZarer\n",
      "\n",
      "Greek:\n",
      "Aanara\t\tAarara\n",
      "Barara\t\tBaran\n",
      "Coana\t\tCarara\n",
      "Darara\t\tDarera\n",
      "Eararer\t\tEaraer\n",
      "Faran\t\tFoana\t\tFarare\n",
      "Garara\t\tGaran\n",
      "Harara\t\tHorara\t\tHararer\n",
      "Iarera\t\tIarara\n",
      "Jarara\t\tJanarer\t\tJararer\n",
      "Karara\t\tKaran\n",
      "Larara\t\tLaran\n",
      "Morara\t\tMaran\t\tMarara\n",
      "Nararan\t\tNarara\n",
      "Oarara\n",
      "Panara\t\tParara\n",
      "Qarara\n",
      "Rarara\n",
      "Sarara\t\tSararer\t\tSarera\n",
      "Toarar\t\tTarara\n",
      "Uarara\t\tUiarar\t\tUararer\n",
      "Vararar\t\tVarara\n",
      "Woara\t\tWarana\t\tWarara\n",
      "Xarara\n",
      "Yarara\t\tYaarar\n",
      "Zararar\t\tZarara\n",
      "\n",
      "Hindi:\n",
      "Aanara\t\tAarara\n",
      "Bararar\t\tBarera\t\tBarara\n",
      "Coarar\t\tCaran\t\tCarara\n",
      "Dararar\t\tDarara\t\tDarera\n",
      "Eoarara\t\tEararar\t\tEarara\n",
      "Farera\t\tFarara\n",
      "Garera\t\tGanara\t\tGanera\n",
      "Harer\t\tHarar\t\tHarara\n",
      "Ioarer\t\tIarara\t\tIoarar\n",
      "Jarara\t\tJoana\n",
      "Karara\t\tKararar\t\tKoara\n",
      "Loarara\t\tLarara\t\tLanara\n",
      "Marea\t\tMarara\t\tMaranar\n",
      "Narara\t\tNaarar\n",
      "Oarera\t\tOarara\t\tOaaara\n",
      "Pararar\t\tPoarar\t\tParan\n",
      "Qanara\t\tQarara\n",
      "Rarara\t\tRoarar\t\tRarera\n",
      "Sanara\t\tSoarar\t\tSarara\n",
      "Tarera\t\tTarara\n",
      "Uaran\t\tUarara\t\tUanara\n",
      "Varora\t\tVarara\t\tVaran\n",
      "Woarar\t\tWarara\n",
      "Xarara\n",
      "Yanar\t\tYarara\t\tYoarar\n",
      "Zararar\t\tZarara\n",
      "\n",
      "Irish:\n",
      "Aanara\t\tAanar\n",
      "Berar\t\tBanara\t\tBanarar\n",
      "Caner\t\tCoan\n",
      "Daner\t\tDanara\n",
      "Eanar\t\tEanara\n",
      "Fanara\n",
      "Goan\t\tGaner\t\tGanara\n",
      "Horar\t\tHaner\n",
      "Ianer\t\tIarar\t\tIanara\n",
      "Jarar\t\tJanara\n",
      "Kaner\n",
      "Lanarra\t\tLanear\t\tLaner\n",
      "Manara\t\tMerar\t\tMana\n",
      "Nanara\t\tNanarar\n",
      "Oanara\n",
      "Panara\t\tParar\n",
      "Qanara\t\tQanar\t\tQaner\n",
      "Ranara\t\tRoan\n",
      "Sanara\t\tSanarar\t\tSana\n",
      "Taner\t\tTanee\n",
      "Uanara\t\tUanan\t\tUrane\n",
      "Vanara\n",
      "Waner\t\tWarar\t\tWanara\n",
      "Xana\t\tXanara\n",
      "Yarar\t\tYanara\n",
      "Zanara\t\tZaner\t\tZana\n",
      "\n",
      "Italian:\n",
      "Aorer\t\tAarara\n",
      "Baner\t\tBanee\t\tBarar\n",
      "Carar\t\tCaran\n",
      "Dorer\t\tDarar\n",
      "Earar\t\tEorrer\n",
      "Farere\t\tFarar\n",
      "Garar\t\tGaran\n",
      "Haner\t\tHerer\n",
      "Iaran\t\tIarar\n",
      "Jarar\t\tJarer\n",
      "Karar\n",
      "Leree\t\tLarara\t\tLaran\n",
      "Morer\t\tMaran\n",
      "Narar\n",
      "Ooara\t\tOarar\n",
      "Parar\t\tParan\n",
      "Qaner\n",
      "Rarar\t\tRorar\n",
      "Sarar\t\tSarer\t\tSorer\n",
      "Tarar\t\tTara\t\tTaree\n",
      "Uarar\n",
      "Varar\n",
      "Waran\t\tWorar\t\tWerer\n",
      "Xarar\n",
      "Yanere\t\tYaner\n",
      "Zarar\t\tZaner\n",
      "\n",
      "Japanese:\n",
      "Aanara\t\tAarera\t\tAarara\n",
      "Baner\t\tBanara\n",
      "Cararare\t\tCarar\t\tCarara\n",
      "Darara\n",
      "Earara\n",
      "Farara\t\tFararar\n",
      "Garara\n",
      "Harara\n",
      "Ioara\t\tIarara\t\tIerara\n",
      "Jarara\n",
      "Karara\t\tKararar\n",
      "Loara\t\tLarara\n",
      "Marana\t\tMarara\n",
      "Narara\n",
      "Oaana\t\tOanara\t\tOaara\n",
      "Panara\t\tParara\t\tParan\n",
      "Qanara\t\tQoara\t\tQanar\n",
      "Rarara\n",
      "Saroa\t\tSarara\n",
      "Taree\t\tTara\t\tTarara\n",
      "Uararar\t\tUarara\n",
      "Varer\t\tVarara\n",
      "Warer\t\tWarara\n",
      "Xarara\t\tXanarar\n",
      "Yarer\t\tYarara\n",
      "Zoara\t\tZarara\n",
      "\n",
      "Korean:\n",
      "Aane\n",
      "Bane\n",
      "Cone\t\tCane\n",
      "Dane\n",
      "Eane\n",
      "Fane\n",
      "Gane\n",
      "Hane\t\tHare\n",
      "Iare\t\tIaner\t\tIane\n",
      "Jane\t\tJaner\n",
      "Kore\t\tKan\n",
      "Lane\t\tLan\n",
      "Man\n",
      "Nane\t\tNore\t\tNan\n",
      "Oane\n",
      "Pan\n",
      "Qane\t\tQare\n",
      "Rane\n",
      "San\t\tSara\n",
      "Tan\n",
      "Uane\t\tUare\n",
      "Vare\t\tVan\t\tVane\n",
      "Wane\n",
      "Xane\t\tXaner\n",
      "Yare\t\tYane\t\tYon\n",
      "Zare\t\tZane\n",
      "\n",
      "Polish:\n",
      "Aarer\t\tAorer\n",
      "Banee\t\tBaner\n",
      "Cora\t\tCarere\n",
      "Darere\t\tDarer\n",
      "Earere\t\tEarer\n",
      "Farar\n",
      "Garar\t\tGaner\t\tGare\n",
      "Haner\t\tHaree\n",
      "Iarer\t\tIora\n",
      "Jaree\t\tJaan\t\tJarer\n",
      "Karer\t\tKarar\n",
      "Larar\t\tLarer\t\tLaner\n",
      "Moree\t\tMarer\n",
      "Naree\t\tNarer\n",
      "Ooare\t\tOarar\t\tOaran\n",
      "Parer\t\tParar\t\tPara\n",
      "Qanee\t\tQaner\n",
      "Rarer\t\tRarar\n",
      "Sarer\t\tSorer\n",
      "Tarer\t\tTorer\n",
      "Uarar\n",
      "Varar\t\tVarer\n",
      "Waree\t\tWarer\n",
      "Xarar\n",
      "Yarer\t\tYaree\n",
      "Zarer\t\tZorer\n",
      "\n",
      "Portuguese:\n",
      "Aarer\n",
      "Baner\t\tBarer\n",
      "Carer\n",
      "Dorer\t\tDaree\t\tDarer\n",
      "Earer\n",
      "Farer\t\tFaner\n",
      "Garar\t\tGaner\t\tGarer\n",
      "Harer\t\tHanee\n",
      "Iarer\t\tIarar\n",
      "Jaree\t\tJarer\n",
      "Karer\t\tKaarere\t\tKaree\n",
      "Larer\t\tLanee\n",
      "Marer\t\tMarar\t\tMararar\n",
      "Narer\n",
      "Oarer\t\tOaner\n",
      "Paner\t\tParer\t\tPorer\n",
      "Qarer\t\tQarar\n",
      "Rarer\t\tRarar\t\tRaree\n",
      "Sanee\t\tSare\t\tSorer\n",
      "Tarer\t\tTorer\t\tTanee\n",
      "Uarar\t\tUarer\n",
      "Varer\t\tVorer\t\tVanrer\n",
      "Waner\t\tWorer\t\tWarer\n",
      "Xarrer\t\tXarar\t\tXarer\n",
      "Yarar\t\tYarere\t\tYarer\n",
      "Zarer\n",
      "\n",
      "Russian:\n",
      "Aaner\t\tAarara\n",
      "Barara\t\tBaner\n",
      "Carara\t\tCaner\t\tCaana\n",
      "Dorara\t\tDanee\t\tDarer\n",
      "Eaner\t\tEanara\n",
      "Foana\t\tFaner\t\tFoara\n",
      "Ganer\n",
      "Haner\t\tHoner\t\tHanera\n",
      "Ianer\n",
      "Jarara\t\tJaner\n",
      "Kaner\t\tKanee\n",
      "Laner\t\tLanee\n",
      "Manara\t\tMoner\t\tManer\n",
      "Naner\t\tNanee\n",
      "Ooara\t\tOaner\t\tOanara\n",
      "Paner\t\tPoran\n",
      "Qanoer\t\tQaner\n",
      "Ranara\t\tRaner\n",
      "Sanee\t\tSaner\n",
      "Taner\n",
      "Uaner\t\tUanera\n",
      "Vaner\n",
      "Wean\t\tWaner\n",
      "Xanar\t\tXanara\n",
      "Yanere\t\tYaner\n",
      "Zarar\t\tZaner\n",
      "\n",
      "Scottish:\n",
      "Aarer\t\tAoner\n",
      "Borer\t\tBarer\n",
      "Carer\n",
      "Daran\t\tDaner\t\tDarer\n",
      "Earere\t\tEaare\n",
      "Farer\t\tFarar\n",
      "Garer\n",
      "Harer\t\tHaree\n",
      "Iarer\n",
      "Jareere\t\tJarer\t\tJaner\n",
      "Karer\t\tKarar\t\tKaree\n",
      "Larer\n",
      "Marer\n",
      "Noner\t\tNarar\n",
      "Oarer\t\tOaree\n",
      "Parer\t\tPoree\t\tPorer\n",
      "Qarer\t\tQoree\n",
      "Rarer\t\tRarar\n",
      "Sarer\t\tSorer\n",
      "Taree\t\tTara\t\tTaner\n",
      "Uarer\n",
      "Varere\t\tVarer\n",
      "Warar\t\tWarer\n",
      "Xanee\t\tXarer\n",
      "Yarer\t\tYirer\n",
      "Zarer\t\tZaree\n",
      "\n",
      "Spanish:\n",
      "Aaner\t\tAarerer\t\tAarar\n",
      "Boarar\t\tBarar\t\tBarer\n",
      "Carara\t\tCarar\n",
      "Dara\t\tDarar\n",
      "Earar\t\tEoara\t\tEarara\n",
      "Farar\n",
      "Garar\t\tGarara\n",
      "Hara\t\tHarar\n",
      "Iarara\t\tIarar\n",
      "Jarar\t\tJarer\n",
      "Karer\t\tKarar\n",
      "Larar\t\tLoan\n",
      "Marar\n",
      "Nara\t\tNarar\n",
      "Oarara\t\tOarer\n",
      "Paner\t\tParar\t\tParan\n",
      "Qarara\t\tQaner\n",
      "Rarer\t\tRarar\n",
      "Soare\t\tSarar\n",
      "Tarar\n",
      "Uarar\t\tUoara\t\tUara\n",
      "Varar\t\tVoara\n",
      "Woare\t\tWoara\t\tWarar\n",
      "Xara\t\tXaner\n",
      "Yarar\t\tYoaer\t\tYaner\n",
      "Zarar\n",
      "\n",
      "Vietnamese:\n",
      "Aore\t\tAan\n",
      "Ban\t\tBon\n",
      "Can\n",
      "Dan\n",
      "Eon\t\tEan\n",
      "Fan\t\tFare\n",
      "Gan\t\tGare\n",
      "Han\t\tHon\n",
      "Iare\t\tIon\n",
      "Jane\t\tJan\t\tJon\n",
      "Kan\n",
      "Lan\n",
      "Man\n",
      "Nan\n",
      "Oan\t\tOoa\t\tOoan\n",
      "Pan\n",
      "Qan\n",
      "Ran\n",
      "San\t\tSore\n",
      "Tan\n",
      "Uaner\t\tUan\n",
      "Van\n",
      "Wan\n",
      "Xara\t\tXan\n",
      "Yan\t\tYara\n",
      "Zare\t\tZan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_to_code:\n",
    "    samples(cat, rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's not great.  It'd be hard to tell which language these \"names\" were supposed to be in.  Our model hasn't trained for long enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastname_rnn = rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(lastname_rnn,\"lastname_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a better model - 512 hidden units, trained for 100,000 epochs (~10 mins)\n",
    "lastname_rnn = torch.load(\"lastname_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic:\n",
      "Araha\n",
      "Bara\n",
      "Chara\t\tChari\n",
      "Danar\t\tDana\n",
      "Eana\t\tEara\n",
      "Fara\t\tFanda\t\tFoura\n",
      "Gara\n",
      "Hana\t\tHoura\n",
      "Iara\t\tIari\n",
      "Jana\t\tJamar\t\tJour\n",
      "Kouma\t\tKaris\t\tKana\n",
      "Lour\t\tLana\n",
      "Mora\t\tMara\n",
      "Namar\n",
      "Ohara\t\tOaram\t\tOamar\n",
      "Para\n",
      "Quar\t\tQara\t\tQana\n",
      "Ramar\n",
      "Sama\t\tShama\t\tSana\n",
      "Taram\t\tTamin\t\tTara\n",
      "Uaram\t\tUara\n",
      "Vana\t\tVanda\t\tVaram\n",
      "Wouran\t\tWaram\t\tWanda\n",
      "Xara\t\tXana\t\tXaram\n",
      "Yana\t\tYanar\n",
      "Zari\t\tZamar\t\tZana\n",
      "\n",
      "Chinese:\n",
      "Aun\t\tAng\n",
      "Bau\n",
      "Can\t\tChon\t\tCha\n",
      "Dun\t\tDon\n",
      "Eun\n",
      "Fa\t\tFun\n",
      "Guang \t\tGuan\t\tGuang\n",
      "Han\t\tHann\n",
      "Iunge\t\tIun\n",
      "Jan\n",
      "Ka\t\tKan\n",
      "Lan\n",
      "Man\n",
      "Nan\t\tNing\n",
      "Oha\n",
      "Pai\t\tPan\n",
      "Qun\t\tQan\n",
      "Ran\t\tRou\n",
      "Shan\t\tSha\n",
      "Tan\t\tThan\n",
      "Uun\t\tUue\n",
      "Van\n",
      "Wange\t\tWan\n",
      "Xin\t\tXun\n",
      "Yan\t\tYai\t\tYau\n",
      "Zhan\n",
      "\n",
      "Czech:\n",
      "Allan\n",
      "Ballan\t\tBalla\n",
      "Challa\t\tChara\t\tCare\n",
      "Dallan\t\tDaner\n",
      "Erak\t\tEran\n",
      "Faricha\t\tFarich\n",
      "Gorek\t\tGaren\t\tGarenck\n",
      "Hander\t\tHandent\t\tHolla\n",
      "Irane\t\tIran\t\tIalla\n",
      "Jander\t\tJaner\n",
      "Kari\t\tKalla\t\tKolla\n",
      "Lana\t\tLanerr\t\tLaner\n",
      "Mara\n",
      "Nalle\t\tNalla\n",
      "Ollan\t\tOrrach\t\tOrtan\n",
      "Palle\t\tPare\n",
      "Qarek\t\tQaren\n",
      "Romall\t\tRoman\n",
      "Sallan\t\tSalla\t\tSalle\n",
      "Tran\n",
      "Uran\t\tUrich\n",
      "Villa\t\tVanter\t\tVanterk\n",
      "Wolla\t\tWalla\n",
      "Xalla\n",
      "Yonek\t\tYaner\n",
      "Zana\t\tZaner\n",
      "\n",
      "Dutch:\n",
      "Anen\t\tAner\n",
      "Beren\n",
      "Canter\t\tCher\n",
      "Denen\t\tDener\n",
      "Eeren\t\tEere\n",
      "Fenter\t\tFeeren\t\tFeer\n",
      "Geren\t\tGaner\t\tGaren\n",
      "Haner\t\tHoner\n",
      "Ieren\n",
      "Jener\t\tJamen\n",
      "Kouner\t\tKoner\t\tKoune\n",
      "Loun\t\tLener\n",
      "Merten\t\tManer\n",
      "Nander\t\tNaner\n",
      "Orener\n",
      "Paner\t\tPant\t\tPeren\n",
      "Qerin\t\tQaner\t\tQeren\n",
      "Rone\n",
      "Santer\t\tSanten\t\tSantone\n",
      "Toune\t\tToulen\n",
      "Ueren\n",
      "Veren\t\tVaner\n",
      "Want\t\tWante\n",
      "Xeren\t\tXander\n",
      "Yaners\t\tYaner\n",
      "Zanerren\t\tZaner\t\tZanger\n",
      "\n",
      "English:\n",
      "Allen\t\tAlen\t\tArten\n",
      "Banger\t\tBang\t\tBand\n",
      "Chander\t\tCander\n",
      "Dongel\t\tDonger\n",
      "Eringen\t\tErin\t\tErishe\n",
      "Farten\n",
      "Gander\t\tGanger\n",
      "Hander\n",
      "Iring\t\tIollen\n",
      "Jang\t\tJanger\n",
      "Konger\n",
      "Longer\t\tLallen\n",
      "Mallen\t\tMalle\n",
      "Nander\n",
      "Ollen\t\tOrton\t\tOrtent\n",
      "Pandon\t\tPander\n",
      "Qanger\t\tQarten\t\tQonger\n",
      "Rongelen\t\tRongel\n",
      "Sarter\t\tSanter\t\tSanton\n",
      "Tongel\t\tTonger\n",
      "Uongel\t\tUolle\n",
      "Vang\t\tVonger\t\tVanger\n",
      "Wallen\t\tWander\t\tWanderten\n",
      "Xandon\t\tXanger\n",
      "Yaler\t\tYallen\t\tYanger\n",
      "Zoner\t\tZang\t\tZangert\n",
      "\n",
      "French:\n",
      "Arten\n",
      "Bare\t\tBaner\n",
      "Care\n",
      "Danger\t\tDaner\t\tDangar\n",
      "Eaner\t\tEare\n",
      "Fariene\t\tFarien\n",
      "Garen\n",
      "Hanger\t\tHangan\n",
      "Ianer\t\tIerin\n",
      "Joner\t\tJaner\n",
      "Kaner\t\tKaler\t\tKoune\n",
      "Lenger\t\tLare\t\tLaner\n",
      "Merten\t\tMarten\t\tMare\n",
      "Nerin\t\tNaren\n",
      "Oraner\n",
      "Pare\n",
      "Qane\t\tQaner\t\tQurin\n",
      "Rouler\t\tRomer\t\tRouri\n",
      "Santer\t\tSarin\n",
      "Tarin\t\tToullen\t\tTare\n",
      "Uaner\t\tUanerte\n",
      "Vaner\t\tVeriner\n",
      "Wanter\t\tWaren\n",
      "Xanerte\t\tXaner\n",
      "Yanert\t\tYaner\n",
      "Zoure\t\tZaner\n",
      "\n",
      "German:\n",
      "Allen\t\tAler\n",
      "Berten\n",
      "Cher\t\tConger\n",
      "Dennerr\t\tDenger\n",
      "Eren\n",
      "Ferten\n",
      "Gangel\t\tGangh\t\tGaren\n",
      "Hanger\t\tHang\n",
      "Iren\t\tIere\n",
      "Jangel\t\tJang\t\tJareng\n",
      "Kanger\t\tKoner\n",
      "Leren\t\tLere\n",
      "Manger\t\tManter\n",
      "Naner\n",
      "Oren\n",
      "Paner\t\tParen\n",
      "Quren\t\tQures\n",
      "Romer\t\tRonger\n",
      "Santer\t\tSaller\t\tSanther\n",
      "Trem\t\tTren\t\tTrent\n",
      "Uerten\t\tUeren\t\tUanger\n",
      "Veren\t\tVerthe\t\tVerten\n",
      "Wanter\n",
      "Xeren\t\tXerten\t\tXerther\n",
      "Yangar\t\tYerter\t\tYanger\n",
      "Zangerr\t\tZaner\t\tZangel\n",
      "\n",
      "Greek:\n",
      "Allis\t\tAllino\t\tAllani\n",
      "Baris\n",
      "Caris\t\tCoris\t\tCaritos\n",
      "Danis\n",
      "Earis\t\tEranis\t\tErastoulos\n",
      "Farison\t\tFaris\n",
      "Garis\n",
      "Hanis\t\tHaristi\n",
      "Iarian\t\tIaris\t\tIalis\n",
      "Jangalos\t\tJanis\t\tJanitos\n",
      "Kalitos\t\tKarisolo\t\tKastilos\n",
      "Lanitoulis\t\tLanis\n",
      "Maris\t\tMolos\t\tMorialos\n",
      "Naris\n",
      "Orasani\t\tOrasanis\n",
      "Panis\t\tPoris\t\tPantis\n",
      "Qaris\n",
      "Rostiosto\t\tRostilos\n",
      "Sallis\t\tSallas\t\tSallasi\n",
      "Tarisolo\t\tToris\t\tTarialoso\n",
      "Uaris\t\tUarisolo\n",
      "Varas\t\tVanis\n",
      "Waris\n",
      "Xarian\t\tXalinos\t\tXarisolo\n",
      "Yanis\t\tYangalos\n",
      "Zanis\t\tZanitas\n",
      "\n",
      "Hindi:\n",
      "Arthan\t\tArtan\n",
      "Bander\t\tBandan\n",
      "Chand\t\tChandan\n",
      "Dandan\t\tDangara\t\tDungara\n",
      "Eana\t\tErana\n",
      "Farin\t\tFertan\n",
      "Gandan\n",
      "Handa\t\tHander\t\tHandan\n",
      "Iandan\t\tIanan\n",
      "Jaran\t\tJandan\t\tJaman\n",
      "Kandan\t\tKana\n",
      "Langaran\t\tLana\n",
      "Maran\t\tMarahar\n",
      "Nani\t\tNanan\t\tNarin\n",
      "Orana\n",
      "Pander\t\tPana\n",
      "Qanaman\t\tQanan\n",
      "Rana\t\tRani\n",
      "Sandara\t\tSaran\t\tSanthan\n",
      "Tana\t\tTanan\n",
      "Uana\t\tUananda\n",
      "Vandan\t\tVandin\n",
      "Wandan\n",
      "Xanan\t\tXana\n",
      "Yingara\t\tYanghan\t\tYangara\n",
      "Zana\n",
      "\n",
      "Irish:\n",
      "Allan\t\tAngan\t\tAlaran\n",
      "Bollang\t\tBanghar\t\tBanghan\n",
      "Changan\t\tChallan\t\tChellan\n",
      "Dananghan\t\tDonghin\t\tDanghand\n",
      "Eonghinn\t\tEanghan\t\tEalla\n",
      "Fanghan\t\tFanghall\n",
      "Ganghann\t\tGanghan\n",
      "Hanghan\t\tHonghin\n",
      "Iangan\t\tIallan\t\tIanghan\n",
      "Janden\t\tJallen\t\tJallan\n",
      "Kanallan\t\tKanghan\n",
      "Langan\t\tLanghan\t\tLananghan\n",
      "Manghan\n",
      "Nanan\t\tNanallann\n",
      "Oranan\t\tOranghan\n",
      "Panan\t\tPallan\t\tPonghin\n",
      "Qallan\t\tQanghan\n",
      "Ronghin\n",
      "Sanghan\t\tSanghin\n",
      "Tanghan\n",
      "Uanghan\t\tUonghill\n",
      "Vanghan\t\tVanghand\n",
      "Wangan\t\tWanghan\n",
      "Xanghelland\t\tXanghan\t\tXanghallan\n",
      "Yallan\t\tYanghan\t\tYanden\n",
      "Zangan\t\tZanghan\t\tZanghar\n",
      "\n",
      "Italian:\n",
      "Alani\t\tArtin\n",
      "Bangani\t\tBangan\n",
      "Canto\t\tCantin\n",
      "Dangani\t\tDonton\n",
      "Eangani\t\tEantin\n",
      "Farin\t\tFarini\n",
      "Gartin\t\tGarin\n",
      "Hangari\t\tHangini\n",
      "Iangani\t\tIongali\t\tIangon\n",
      "Jangari\n",
      "Kangar\t\tKangari\n",
      "Langari\t\tLangini\t\tLangar\n",
      "Marichi\n",
      "Nanit\n",
      "Orichili\t\tOrichilit\n",
      "Pantin\n",
      "Qangini\t\tQangani\n",
      "Rongalo\t\tRongali\n",
      "Santon\t\tSantin\n",
      "Tangani\t\tTanganit\n",
      "Uangani\n",
      "Vangani\t\tVingeri\n",
      "Wangani\t\tWantin\n",
      "Xongalo\t\tXangani\n",
      "Yangeri\t\tYangili\t\tYangari\n",
      "Zangari\t\tZongalo\t\tZongari\n",
      "\n",
      "Japanese:\n",
      "Araka\t\tArtan\n",
      "Bani\t\tBouma\t\tBana\n",
      "Chaima\t\tChama\t\tCurima\n",
      "Damamama\t\tDamam\t\tDamama\n",
      "Euka\t\tEaka\n",
      "Fangara\t\tFouma\n",
      "Gana\t\tGaman\n",
      "Hana\t\tHouma\n",
      "Iuka\t\tIaka\t\tIana\n",
      "Janaka\t\tJangara\n",
      "Kaman\t\tKamama\n",
      "Lamima\t\tLamama\n",
      "Maka\n",
      "Nishi\t\tNaka\t\tNamam\n",
      "Oaka\n",
      "Pana\n",
      "Qamama\t\tQuman\n",
      "Ramama\t\tRamia\n",
      "Sakama\t\tSaka\t\tSakam\n",
      "Taka\n",
      "Uaka\t\tUamama\t\tUamima\n",
      "Vina\t\tVana\n",
      "Wangara\n",
      "Xishia\t\tXamama\t\tXamaka\n",
      "Yana\n",
      "Zanaka\n",
      "\n",
      "Korean:\n",
      "Ang\n",
      "Bon\n",
      "Chon\n",
      "Donn\t\tDon\n",
      "Eonn\t\tEon\n",
      "Foun\t\tFon\t\tFo\n",
      "Gon\n",
      "Han\t\tHon\n",
      "Ionn\t\tIong\t\tIon\n",
      "Ja\t\tJon\n",
      "Kon\t\tKou\n",
      "Lon\n",
      "Man\n",
      "Noun\t\tNon\n",
      "Ohon\n",
      "Pan\n",
      "Qun\n",
      "Ron\n",
      "Sho\n",
      "Ton\t\tThon\n",
      "Uon\n",
      "Von\n",
      "Won\t\tWong\n",
      "Xon\t\tXong\n",
      "Yan\t\tYon\n",
      "Zhon\t\tZhung\n",
      "\n",
      "Polish:\n",
      "Allan\t\tAlakin\n",
      "Ballan\t\tBallo\t\tBalen\n",
      "Chandon\t\tChang\t\tChand\n",
      "Dongan\t\tDowaki\t\tDonger\n",
      "Eriend\t\tErin\n",
      "Farin\t\tFander\n",
      "Golla\n",
      "Hangan\t\tHander\n",
      "Iolong\t\tIollan\t\tIollo\n",
      "Jonek\t\tJanew\t\tJander\n",
      "Kollan\t\tKolek\t\tKolow\n",
      "Lanek\t\tLander\n",
      "Mallan\t\tMalla\n",
      "Nakar\t\tNakan\n",
      "Oriell\t\tOrisko\n",
      "Paner\t\tPanderk\t\tPander\n",
      "Qonek\t\tQoneki\n",
      "Riman\t\tRoman\n",
      "Sander\t\tSanderki\n",
      "Tander\t\tTollan\n",
      "Uollan\t\tUonell\t\tUolek\n",
      "Vonder\t\tVander\n",
      "Wallan\n",
      "Xallan\t\tXandenk\t\tXander\n",
      "Yander\n",
      "Zonek\t\tZanden\t\tZallan\n",
      "\n",
      "Portuguese:\n",
      "Arter\n",
      "Bari\t\tBare\n",
      "Cares\n",
      "Daner\t\tDangel\n",
      "Eanera\t\tEares\n",
      "Fares\t\tFarran\n",
      "Gares\n",
      "Hares\t\tHorra\n",
      "Iare\t\tIara\t\tIerras\n",
      "Jore\t\tJares\t\tJarer\n",
      "Kare\n",
      "Lare\n",
      "Manei\t\tMares\n",
      "Nares\t\tNaner\n",
      "Oraser\n",
      "Perra\t\tPares\n",
      "Qares\n",
      "Rosta\t\tRaner\n",
      "Sarer\n",
      "Tares\t\tToura\n",
      "Uara\t\tUares\n",
      "Vares\n",
      "Wares\t\tWare\n",
      "Xares\n",
      "Yares\t\tYarese\t\tYaner\n",
      "Zaris\t\tZaner\t\tZaler\n",
      "\n",
      "Russian:\n",
      "Allavev\t\tAllin\n",
      "Barin\t\tBarishov\n",
      "Chani\t\tChillen\n",
      "Danikh\t\tDamanov\t\tDakinov\n",
      "Eaninov\t\tErishin\t\tEarino\n",
      "Farin\t\tFarinov\n",
      "Garin\n",
      "Hander\t\tHandon\n",
      "Iarickov\t\tIarinov\t\tIanovent\n",
      "Janin\t\tJanev\t\tJaner\n",
      "Kovanov\t\tKaniel\n",
      "Lakin\t\tLanikov\n",
      "Marinov\n",
      "Nakin\n",
      "Orishovev\t\tOrishov\n",
      "Parisho\t\tParin\t\tParano\n",
      "Qaniel\t\tQarinov\n",
      "Rovanov\t\tRakin\n",
      "Shillov\t\tSanton\t\tSantonovev\n",
      "Tarinov\n",
      "Uanien\t\tUaniel\t\tUoverov\n",
      "Vaniel\t\tVander\n",
      "Wander\t\tWantonov\t\tWanten\n",
      "Xinoven\t\tXaniel\n",
      "Yanikov\t\tYanikol\n",
      "Zaninov\n",
      "\n",
      "Scottish:\n",
      "Arten\t\tArrin\n",
      "Bricch\t\tBrin\t\tBang\n",
      "Chant\n",
      "Danger\t\tDonn\t\tDonno\n",
      "Ellin\t\tErin\n",
      "Fangell\t\tFrin\t\tFanger\n",
      "Ganger\n",
      "Hander\t\tHangell\n",
      "Irin\n",
      "Janger\t\tJinger\n",
      "Kongers\t\tKonn\t\tKonger\n",
      "Linger\t\tLang\n",
      "Manter\t\tManten\n",
      "Nanger\t\tNangert\n",
      "Oringell\t\tOllon\t\tOrtent\n",
      "Panter\t\tPertan\n",
      "Qurten\n",
      "Rong\t\tRang\n",
      "Santer\n",
      "Tring\t\tTrich\t\tTrong\n",
      "Uring\n",
      "Vallenn\t\tVanger\t\tVinger\n",
      "Wantern\t\tWanter\t\tWong\n",
      "Xangell\t\tXongell\t\tXanger\n",
      "Yong\t\tYarter\t\tYang\n",
      "Zarten\t\tZanger\t\tZangert\n",
      "\n",
      "Spanish:\n",
      "Aran\n",
      "Bari\t\tBaner\n",
      "Cari\t\tCarin\t\tCare\n",
      "Dangaran\t\tDongala\t\tDangala\n",
      "Eran\t\tEare\n",
      "Fari\t\tFerra\t\tFandel\n",
      "Gareri\t\tGarera\t\tGarer\n",
      "Handel\t\tHonder\t\tHangala\n",
      "Iara\t\tIari\n",
      "Jana\t\tJara\t\tJaner\n",
      "Kara\n",
      "Laner\t\tLara\t\tLangar\n",
      "Mara\n",
      "Nari\t\tNarer\t\tNoulla\n",
      "Oranalla\t\tOrana\n",
      "Parer\t\tParen\t\tPara\n",
      "Qaran\t\tQara\n",
      "Roner\n",
      "Santar\t\tSantara\t\tSertan\n",
      "Tara\t\tTrana\t\tTari\n",
      "Uara\n",
      "Vangaran\t\tVeran\t\tVangala\n",
      "Wari\n",
      "Xara\t\tXana\n",
      "Yongal\t\tYongala\t\tYangala\n",
      "Zaner\t\tZanella\n",
      "\n",
      "Vietnamese:\n",
      "An\n",
      "Ban\t\tBun\n",
      "Chan\n",
      "Dun\n",
      "Eung\t\tEun\n",
      "Fun\t\tFan\n",
      "Gue\t\tGuan\n",
      "Han\n",
      "Iun\t\tIuan\n",
      "Jan\t\tJau\n",
      "Kan\n",
      "Lan\t\tLa\n",
      "Mou\t\tMan\n",
      "Nan\n",
      "Ohang\t\tOhan\n",
      "Pan\t\tPhan\n",
      "Qun\t\tQan\t\tQuan\n",
      "Rou\n",
      "Sha\n",
      "Thun\t\tTa\t\tThang\n",
      "Uhan\t\tUun\t\tUha\n",
      "Van\n",
      "Wan\n",
      "Xuun\t\tXun\n",
      "Yan\t\tYang\n",
      "Zhan\t\tZhon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_to_code:\n",
    "    samples(cat, lastname_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so there are some plausible last names (maybe).  What about first names?  Let's load up some first name data and train the same network on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 2 ['English', 'Spanish']\n"
     ]
    }
   ],
   "source": [
    "# Build the category_lines dictionary, a list of lines per category\n",
    "fn_category_lines = {}\n",
    "fn_all_categories = []\n",
    "for filename in findFiles('data/firstnames/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    fn_all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    fn_category_lines[category] = lines\n",
    "\n",
    "fn_n_categories = len(fn_all_categories)\n",
    "\n",
    "if fn_n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', fn_n_categories, fn_all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (1000 10%) 3.2739\n",
      "0m 6s (2000 20%) 3.4480\n",
      "0m 10s (3000 30%) 2.7070\n",
      "0m 13s (4000 40%) 3.2199\n",
      "0m 16s (5000 50%) 2.9055\n",
      "0m 20s (6000 60%) 3.0249\n",
      "0m 23s (7000 70%) 2.2627\n",
      "0m 27s (8000 80%) 2.9139\n",
      "0m 30s (9000 90%) 2.1260\n",
      "0m 34s (10000 100%) 2.1554\n"
     ]
    }
   ],
   "source": [
    "firstname_rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 10000\n",
    "print_every = 1000\n",
    "plot_every = 100\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    ex = randomTrainingExample(fn_all_categories,fn_category_lines)\n",
    "    output, loss = train(firstname_rnn,*ex)\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'English': 'ENG', 'Spanish': 'SPA'}\n"
     ]
    }
   ],
   "source": [
    "cat_to_code = {}\n",
    "for i in range(fn_n_categories):\n",
    "    cat_to_code[fn_all_categories[i]] = fn_all_categories[i][:3].upper()\n",
    "print(cat_to_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:\n",
      "Aarin\t\tAarina\t\tAerei\n",
      "Barin\t\tBarie\t\tBerin\n",
      "Carie\t\tCarin\n",
      "Dare\t\tDarin\n",
      "Eerin\t\tEarin\n",
      "Farin\t\tFanien\t\tFane\n",
      "Garin\n",
      "Harin\t\tHaria\t\tHare\n",
      "Iarin\t\tIare\n",
      "Jarin\t\tJerina\t\tJaie\n",
      "Kare\t\tKanie\t\tKarin\n",
      "Larin\t\tLarie\n",
      "Marinae\t\tMarin\n",
      "Narin\t\tNarine\n",
      "Oane\t\tOarin\n",
      "Parin\t\tPare\n",
      "Qerin\t\tQarin\n",
      "Rarin\n",
      "Sarie\t\tSare\t\tSarin\n",
      "Tarin\t\tTaren\n",
      "Uarine\t\tUanie\t\tUarin\n",
      "Varin\t\tVare\n",
      "Warin\t\tWarien\n",
      "Xanie\t\tXarin\n",
      "Yarin\t\tYanie\n",
      "Zarin\t\tZerin\n",
      "\n",
      "Spanish:\n",
      "Aarii\t\tAanie\t\tAania\n",
      "Bara\t\tBarii\n",
      "Carii\t\tCariia\t\tCanii\n",
      "Darii\n",
      "Earii\t\tEaria\n",
      "Farii\t\tFaria\t\tFinii\n",
      "Garii\t\tGariia\n",
      "Hirii\t\tHarii\n",
      "Iaiia\t\tIarii\n",
      "Jaria\t\tJariia\t\tJariin\n",
      "Kara\t\tKarii\n",
      "Lara\t\tLarii\t\tLanii\n",
      "Marii\n",
      "Nanii\t\tNarii\n",
      "Oarii\n",
      "Parii\n",
      "Qarii\n",
      "Rariin\t\tRarii\n",
      "Sarii\t\tSariia\n",
      "Tarii\t\tTaria\n",
      "Uanii\t\tUarii\n",
      "Verii\t\tVarii\t\tVenii\n",
      "Wariia\t\tWarii\t\tWara\n",
      "Xara\t\tXariia\n",
      "Yinii\t\tYiniia\t\tYara\n",
      "Zania\t\tZarii\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_to_code:\n",
    "    samples(cat, firstname_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not that great.  Let's load up a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(firstname_rnn,\"firstname_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname_rnn = torch.load(\"firstname_rnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's sample from the two (good) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karina Pander\n",
      "Zandil Gangel\n",
      "Varinel Dongel\n",
      "Qandil Eringer\n",
      "Varine Farten\n",
      "Berin Qanger\n",
      "Gelle Langer\n",
      "Shani Yang\n",
      "Ilinat Xanger\n",
      "Lane Banger\n",
      "Alina Langer\n",
      "Dandil Xonger\n",
      "Handil Orter\n",
      "Shande Dong\n",
      "Nane Mallen\n",
      "Janne Marter\n",
      "Karina Xanger\n",
      "Xandil Qanger\n",
      "Qandil Uong\n",
      "Nane Fander\n",
      "Berin Santer\n",
      "Tandil Nander\n"
     ]
    }
   ],
   "source": [
    "random.seed(random.seed(42))\n",
    "for i in range(22):\n",
    "    f = random.randint(0, 25)\n",
    "    l = random.randint(0, 25)\n",
    "    print(' '.join([sample(\"English\",firstname_rnn,all_letters[f+26]),sample(\"English\",lastname_rnn,all_letters[l+26])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2021 Fighting Baseball roster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
